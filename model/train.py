from keras_text.processing import WordTokenizer

'''
There are a few steps within the model pipeline that can be modified to adjust the 
'''

# tokenizer = WordTokenizer()
# tokenizer.build_vocab(texts)
