{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy\n",
    "Exploring the capabilities of Spacy. \n",
    "\n",
    "**Note:** *If files are not included in the PATH then overwrite.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Model\n",
      "=== Token\n",
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n",
      "=== POS\n",
      "Apple apple PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. u.k. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n",
      "=== Entity\n",
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n",
      "=== Word Vector\n",
      "1.0\n",
      "0.53907\n",
      "0.28761\n",
      "0.53907\n",
      "1.0\n",
      "0.487521\n",
      "0.28761\n",
      "0.487521\n",
      "1.0\n",
      "=== Out of Vocabulary\n",
      "dog True 7.03367 False\n",
      "cat True 6.68082 False\n",
      "banana True 6.70001 False\n",
      "sasquatch True 6.979 False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# Install: pip install spacy && python -m spacy download en\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "\n",
    "# Loading Model\n",
    "print(\"=== Loading Model\")\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "\n",
    "print(\"=== Token\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "print(\"=== POS\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "print(\"=== Entity\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "    \n",
    "print(\"=== Word Vector\")\n",
    "tokens = nlp(u'dog cat banana')\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.similarity(token2))\n",
    "\n",
    "print(\"=== Out of Vocabulary\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "tokens = nlp(u'dog cat banana sasquatch')\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple‚Äôs Siri, available on iPhones, and Amazon‚Äôs Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "class WhitespaceTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __call__(self, text):\n",
    "        words = text.split(' ')\n",
    "        # All tokens 'own' a subsequent space character in this tokenizer\n",
    "        spaces = [True] * len(words)\n",
    "        return Doc(self.vocab, words=words, spaces=spaces)\n",
    "    \n",
    "# Add token\n",
    "nlp = spacy.load('en')\n",
    "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.token.Token' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fdbdc216788c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpatterns_gamer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterminology_gamer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TerminologyFranchise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpatterns_franchise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TerminologyGamer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpatterns_gamer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.Matcher.add\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher._convert_strings\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.token.Token' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load default vocabulary\n",
    "nlp = spacy.load('en')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "#=== Event\n",
    "# Event based\n",
    "EVENT = nlp.vocab.strings['EVENT']\n",
    "\n",
    "def add_event_ent(matcher, doc, i, matches):\n",
    "    # Append entity to doc's entity\n",
    "    match_id, start, end = matches[i]\n",
    "    doc.ents += ((EVENT, start, end),)\n",
    "\n",
    "matcher.add('TheLastJedi', add_event_ent, [{'ORTH': 'The'}, {'ORTH': 'Last'}, {'ORTH': 'Jedi'}])\n",
    "\n",
    "#=== Teminology\n",
    "# Supply Gaming matches\n",
    "terminology_franchise = ['Star Wars', 'Battlefront']\n",
    "terminology_gamer = ['Pay-to-win']\n",
    "\n",
    "# Game S\n",
    "patterns_franchise = [nlp(text) for text in terminology_franchise]\n",
    "patterns_gamer = [nlp(text) for text in terminology_gamer]\n",
    "\n",
    "matcher.add('TerminologyFranchise', None, *patterns_franchise)\n",
    "matcher.add('TerminologyGamer', None, *patterns_gamer)\n",
    "\n",
    "doc = nlp(u\"I think Disney should hit EA for Star Wars Battlefront II. \"\n",
    "          u\"It's a totally Pay-to-win scheme. This is going to definitely affect the launch \",\n",
    "         u\" of The Last Jedi. I'm still gonna watch the last Jedi.\")\n",
    "matches = matcher(doc)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Get the ID of the 'EVENT' entity type. This is required to set an entity.\n",
    "EVENT = nlp.vocab.strings['EVENT']\n",
    "\n",
    "def add_event_ent(matcher, doc, i, matches):\n",
    "    # Get the current match and create tuple of entity label, start and end.\n",
    "    # Append entity to the doc's entity. (Don't overwrite doc.ents!)\n",
    "    match_id, start, end = matches[i]\n",
    "    doc.ents += ((EVENT, start, end),)\n",
    "\n",
    "matcher.add('GoogleIO', add_event_ent,\n",
    "            [{'ORTH': 'Google'}, {'UPPER': 'I'}, {'ORTH': '/'}, {'UPPER': 'O'}],\n",
    "            [{'ORTH': 'Google'}, {'UPPER': 'I'}, {'ORTH': '/'}, {'UPPER': 'O'}, {'IS_DIGIT': True}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = English() # we only want the tokenizer, so no need to load a model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pos_emoji = [u'üòÄ', u'üòÉ', u'üòÇ', u'ü§£', u'üòä', u'üòç'] # positive emoji\n",
    "neg_emoji = [u'üòû', u'üò†', u'üò©', u'üò¢', u'üò≠', u'üòí'] # negative emoji\n",
    "\n",
    "# add patterns to match one or more emoji tokens\n",
    "pos_patterns = [[{'ORTH': emoji}] for emoji in pos_emoji]\n",
    "neg_patterns = [[{'ORTH': emoji}] for emoji in neg_emoji]\n",
    "\n",
    "matcher.add('HAPPY', label_sentiment, *pos_patterns) # add positive pattern\n",
    "matcher.add('SAD', label_sentiment, *neg_patterns) # add negative pattern\n",
    "\n",
    "# add pattern to merge valid hashtag, i.e. '#' plus any ASCII token\n",
    "matcher.add('HASHTAG', merge_hashtag, [{'ORTH': '#'}, {'IS_ASCII': True}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
